{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ryavuz/7week-lesson-feature-engineering?scriptVersionId=200901492\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"#############################################\n# FEATURE ENGINEERING & DATA PRE-PROCESSING\n#############################################\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom fontTools.unicodedata import block\nfrom matplotlib import pyplot as plt\n# !pip install missingno\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 500)\n\ndef load_application_train():\n    data = pd.read_csv(\"/Users/ry/PycharmProjects/pythonProject/pythonProgramlama/python_for_data_science/feature_engineering/datasets/application_train.csv\")\n    return data\n\ndf = load_application_train()\ndf.head()\n\n\ndef load():\n    data = pd.read_csv(\"/Users/ry/PycharmProjects/pythonProject/pythonProgramlama/python_for_data_science/feature_engineering/datasets/titanic.csv\")\n    return data\n\n\ndf = load()\ndf.head()\n\n\n\n#############################################\n# 1. Outliers (Aykırı Değerler)\n#############################################\n\n#############################################\n# Aykırı Değerleri Yakalama\n#############################################\n\n###################\n# Grafik Teknikle Aykırı Değerler\n###################\n\nsns.boxplot(x=df[\"Age\"])\nplt.show(block=True)\n\n###################\n# Aykırı Değerler Nasıl Yakalanır?\n###################\n\nq1 = df[\"Age\"].quantile(0.25)\nq3 = df[\"Age\"].quantile(0.75)\niqr = q3 - q1\nup = q3 + 1.5 * iqr\nlow = q1 - 1.5 * iqr\n\ndf[(df[\"Age\"] < low) | (df[\"Age\"] > up)]\n\ndf[(df[\"Age\"] < low) | (df[\"Age\"] > up)].index\n\n###################\n# Aykırı Değer Var mı Yok mu?\n###################\n\ndf[(df[\"Age\"] < low) | (df[\"Age\"] > up)].any(axis=None)\ndf[(df[\"Age\"] < low)].any(axis=None)\n\n# 1. Eşik değer belirledik.\n# 2. Aykırılara eriştik.\n# 3. Hızlıca aykırı değer var mı yok diye sorduk.\n\n###################\n# İşlemleri Fonksiyonlaştırmak\n###################\n\n\ndef outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\noutlier_thresholds(df, \"Age\")\noutlier_thresholds(df, \"Fare\")\n\nlow, up = outlier_thresholds(df, \"Fare\")\n\ndf[(df[\"Fare\"] < low) | (df[\"Fare\"] > up)].head()\n\n\ndf[(df[\"Fare\"] < low) | (df[\"Fare\"] > up)].index\n\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\ncheck_outlier(df, \"Age\")\ncheck_outlier(df, \"Fare\")\n\n###################\n# grab_col_names\n###################\n\ndff = load_application_train()\ndff.head()\n\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n\n    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.\n\n    Parameters\n    ------\n        dataframe: dataframe\n                Değişken isimleri alınmak istenilen dataframe\n        cat_th: int, optional\n                numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n        car_th: int, optinal\n                kategorik fakat kardinal değişkenler için sınıf eşik değeri\n\n    Returns\n    ------\n        cat_cols: list\n                Kategorik değişken listesi\n        num_cols: list\n                Numerik değişken listesi\n        cat_but_car: list\n                Kategorik görünümlü kardinal değişken listesi\n\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n\n\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n        num_but_cat cat_cols'un içerisinde.\n        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n\n    \"\"\"\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nnum_cols = [col for col in num_cols if col not in \"PassengerId\"]\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))\n\n\ncat_cols, num_cols, cat_but_car = grab_col_names(dff)\n\nnum_cols = [col for col in num_cols if col not in \"SK_ID_CURR\"]\n\nfor col in num_cols:\n    print(col, check_outlier(dff, col))\n\n###################\n# Aykırı Değerlerin Kendilerine Erişmek\n###################\n\ndef grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index\n\ngrab_outliers(df, \"Age\")\n\ngrab_outliers(df, \"Age\", True)\n\nage_index = grab_outliers(df, \"Age\", True)\n\n\noutlier_thresholds(df, \"Age\")\ncheck_outlier(df, \"Age\")\ngrab_outliers(df, \"Age\", True)\n\n#############################################\n# Aykırı Değer Problemini Çözme\n#############################################\n\n###################\n# Silme\n###################\n\nlow, up = outlier_thresholds(df, \"Fare\")\ndf.shape\n\ndf[~((df[\"Fare\"] < low) | (df[\"Fare\"] > up))].shape\n\ndef remove_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers\n\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nnum_cols = [col for col in num_cols if col not in \"PassengerId\"]\n\ndf.shape\n\nfor col in num_cols:\n    new_df = remove_outlier(df, col)\n\ndf.shape[0] - new_df.shape[0]\n\n###################\n# Baskılama Yöntemi (re-assignment with thresholds)\n###################\n\nlow, up = outlier_thresholds(df, \"Fare\")\n\ndf[((df[\"Fare\"] < low) | (df[\"Fare\"] > up))][\"Fare\"]\n\ndf.loc[((df[\"Fare\"] < low) | (df[\"Fare\"] > up)), \"Fare\"]\n\ndf.loc[(df[\"Fare\"] > up), \"Fare\"] = up\n\ndf.loc[(df[\"Fare\"] < low), \"Fare\"] = low\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndf = load()\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\nnum_cols = [col for col in num_cols if col not in \"PassengerId\"]\n\ndf.shape\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))\n\nfor col in num_cols:\n    replace_with_thresholds(df, col)\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))\n\n\n###################\n# Recap\n###################\n\ndf = load()\noutlier_thresholds(df, \"Age\")\ncheck_outlier(df, \"Age\")\ngrab_outliers(df, \"Age\", index=True)\n\nremove_outlier(df, \"Age\").shape\nreplace_with_thresholds(df, \"Age\")\ncheck_outlier(df, \"Age\")\n\n\n\n\n#############################################\n# Çok Değişkenli Aykırı Değer Analizi: Local Outlier Factor\n#############################################\n\n# 17, 3\n\ndf = sns.load_dataset('diamonds')\ndf = df.select_dtypes(include=['float64', 'int64'])\ndf = df.dropna()\ndf.head()\ndf.shape\nfor col in df.columns:\n    print(col, check_outlier(df, col))\n\n\nlow, up = outlier_thresholds(df, \"carat\")\n\ndf[((df[\"carat\"] < low) | (df[\"carat\"] > up))].shape\n\nlow, up = outlier_thresholds(df, \"depth\")\n\ndf[((df[\"depth\"] < low) | (df[\"depth\"] > up))].shape\n\nclf = LocalOutlierFactor(n_neighbors=20)\nclf.fit_predict(df)\n\ndf_scores = clf.negative_outlier_factor_\ndf_scores[0:5]\n# df_scores = -df_scores\nnp.sort(df_scores)[0:5]\n\nscores = pd.DataFrame(np.sort(df_scores))\nscores.plot(stacked=True, xlim=[0, 50], style='.-')\nplt.show(block=True)\n\nth = np.sort(df_scores)[3]\n\ndf[df_scores < th]\n\ndf[df_scores < th].shape\n\n\ndf.describe([0.01, 0.05, 0.75, 0.90, 0.99]).T\n\ndf[df_scores < th].index\n\ndf[df_scores < th].drop(axis=0, labels=df[df_scores < th].index)\n\n\n#############################################\n# Missing Values (Eksik Değerler)\n#############################################\n\n#############################################\n# Eksik Değerlerin Yakalanması\n#############################################\n\ndf = load()\ndf.head()\n\n# eksik gozlem var mı yok mu sorgusu\ndf.isnull().values.any()\n\n# degiskenlerdeki eksik deger sayisi\ndf.isnull().sum()\n\n# degiskenlerdeki tam deger sayisi\ndf.notnull().sum()\n\n# veri setindeki toplam eksik deger sayisi\ndf.isnull().sum().sum()\n\n# en az bir tane eksik degere sahip olan gözlem birimleri\ndf[df.isnull().any(axis=1)]\n\n# tam olan gözlem birimleri\ndf[df.notnull().all(axis=1)]\n\n# Azalan şekilde sıralamak\ndf.isnull().sum().sort_values(ascending=False)\n\n(df.isnull().sum() / df.shape[0] * 100).sort_values(ascending=False)\n\nna_cols = [col for col in df.columns if df[col].isnull().sum() > 0]\n\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns\n\n\nmissing_values_table(df)\n\nmissing_values_table(df, True)\n\n\n#############################################\n# Eksik Değer Problemini Çözme\n#############################################\n\nmissing_values_table(df)\n\n###################\n# Çözüm 1: Hızlıca silmek\n###################\ndf.dropna().shape\n\n###################\n# Çözüm 2: Basit Atama Yöntemleri ile Doldurmak\n###################\n\ndf[\"Age\"].fillna(df[\"Age\"].mean()).isnull().sum()\ndf[\"Age\"].fillna(df[\"Age\"].median()).isnull().sum()\ndf[\"Age\"].fillna(0).isnull().sum()\n\n# df.apply(lambda x: x.fillna(x.mean()), axis=0)\n\ndf.apply(lambda x: x.fillna(x.mean()) if x.dtype != \"O\" else x, axis=0).head()\n\ndff = df.apply(lambda x: x.fillna(x.mean()) if x.dtype != \"O\" else x, axis=0)\n\ndff.isnull().sum().sort_values(ascending=False)\n\ndf[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0]).isnull().sum()\n\ndf[\"Embarked\"].fillna(\"missing\")\n\ndf.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= 10) else x, axis=0).isnull().sum()\n\n###################\n# Kategorik Değişken Kırılımında Değer Atama\n###################\n\n\ndf.groupby(\"Sex\")[\"Age\"].mean()\n\ndf[\"Age\"].mean()\n\ndf[\"Age\"].fillna(df.groupby(\"Sex\")[\"Age\"].transform(\"mean\")).isnull().sum()\n\ndf.groupby(\"Sex\")[\"Age\"].mean()[\"female\"]\n\ndf.loc[(df[\"Age\"].isnull()) & (df[\"Sex\"]==\"female\"), \"Age\"] = df.groupby(\"Sex\")[\"Age\"].mean()[\"female\"]\n\ndf.loc[(df[\"Age\"].isnull()) & (df[\"Sex\"]==\"male\"), \"Age\"] = df.groupby(\"Sex\")[\"Age\"].mean()[\"male\"]\n\ndf.isnull().sum()\n\n#############################################\n# Çözüm 3: Tahmine Dayalı Atama ile Doldurma\n#############################################\n\ndf = load()\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\nnum_cols = [col for col in num_cols if col not in \"PassengerId\"]\ndff = pd.get_dummies(df[cat_cols + num_cols], drop_first=True)\n\ndff.head()\n\n# değişkenlerin standartlatırılması\nscaler = MinMaxScaler()\ndff = pd.DataFrame(scaler.fit_transform(dff), columns=dff.columns)\ndff.head()\n\n\n# knn'in uygulanması.\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5)\ndff = pd.DataFrame(imputer.fit_transform(dff), columns=dff.columns)\ndff.head()\n\ndff = pd.DataFrame(scaler.inverse_transform(dff), columns=dff.columns)\n\ndf[\"age_imputed_knn\"] = dff[[\"Age\"]]\n\ndf.loc[df[\"Age\"].isnull(), [\"Age\", \"age_imputed_knn\"]]\ndf.loc[df[\"Age\"].isnull()]\n\n\n###################\n# Recap\n###################\n\ndf = load()\n# missing table\nmissing_values_table(df)\n# sayısal değişkenleri direk median ile oldurma\ndf.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0).isnull().sum()\n# kategorik değişkenleri mode ile doldurma\ndf.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= 10) else x, axis=0).isnull().sum()\n# kategorik değişken kırılımında sayısal değişkenleri doldurmak\ndf[\"Age\"].fillna(df.groupby(\"Sex\")[\"Age\"].transform(\"mean\")).isnull().sum()\n# Tahmine Dayalı Atama ile Doldurma\n\n\n\n\n#############################################\n# Gelişmiş Analizler\n#############################################\n\n###################\n# Eksik Veri Yapısının İncelenmesi\n###################\n\nmsno.bar(df)\nplt.show()\n\nmsno.matrix(df)\nplt.show()\n\nmsno.heatmap(df)\nplt.show(block=True)\n\n###################\n# Eksik Değerlerin Bağımlı Değişken ile İlişkisinin İncelenmesi\n###################\n\nmissing_values_table(df, True)\nna_cols = missing_values_table(df, True)\n\n\ndef missing_vs_target(dataframe, target, na_columns):\n    temp_df = dataframe.copy()\n\n    for col in na_columns:\n        temp_df[col + '_NA_FLAG'] = np.where(temp_df[col].isnull(), 1, 0)\n\n    na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_NA_\")].columns\n\n    for col in na_flags:\n        print(pd.DataFrame({\"TARGET_MEAN\": temp_df.groupby(col)[target].mean(),\n                            \"Count\": temp_df.groupby(col)[target].count()}), end=\"\\n\\n\\n\")\n\n\nmissing_vs_target(df, \"Survived\", na_cols)\n\n\n\n###################\n# Recap\n###################\n\ndf = load()\nna_cols = missing_values_table(df, True)\n# sayısal değişkenleri direk median ile oldurma\ndf.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0).isnull().sum()\n# kategorik değişkenleri mode ile doldurma\ndf.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= 10) else x, axis=0).isnull().sum()\n# kategorik değişken kırılımında sayısal değişkenleri doldurmak\ndf[\"Age\"].fillna(df.groupby(\"Sex\")[\"Age\"].transform(\"mean\")).isnull().sum()\n# Tahmine Dayalı Atama ile Doldurma\nmissing_vs_target(df, \"Survived\", na_cols)\n\n\n\n\n\n#############################################\n# 3. Encoding (Label Encoding, One-Hot Encoding, Rare Encoding)\n#############################################\n\n#############################################\n# Label Encoding & Binary Encoding\n#############################################\n\ndf = load()\ndf.head()\ndf[\"Sex\"].head()\n\nle = LabelEncoder()\nle.fit_transform(df[\"Sex\"])[0:5]\nle.inverse_transform([0, 1])\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\ndf = load()\n\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2]\n\nfor col in binary_cols:\n    label_encoder(df, col)\n\ndf.head()\n\ndf = load_application_train()\ndf.shape\n\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2]\n\ndf[binary_cols].head()\n\n\nfor col in binary_cols:\n    label_encoder(df, col)\n\n\ndf = load()\ndf[\"Embarked\"].value_counts()\ndf[\"Embarked\"].nunique()\nlen(df[\"Embarked\"].unique())\n\n#############################################\n# One-Hot Encoding\n#############################################\n\ndf = load()\ndf.head()\ndf[\"Embarked\"].value_counts()\n\npd.get_dummies(df, columns=[\"Embarked\"]).head()\n\npd.get_dummies(df, columns=[\"Embarked\"], drop_first=True).head()\n\npd.get_dummies(df, columns=[\"Embarked\"], dummy_na=True).head()\n\npd.get_dummies(df, columns=[\"Sex\", \"Embarked\"], drop_first=True).head()\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\ndf = load()\n\n# cat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]\n\n\none_hot_encoder(df, ohe_cols).head()\n\ndf.head()\n\n#############################################\n# Rare Encoding\n#############################################\n\n# 1. Kategorik değişkenlerin azlık çokluk durumunun analiz edilmesi.\n# 2. Rare kategoriler ile bağımlı değişken arasındaki ilişkinin analiz edilmesi.\n# 3. Rare encoder yazacağız.\n\n###################\n# 1. Kategorik değişkenlerin azlık çokluk durumunun analiz edilmesi.\n###################\n\ndf = load_application_train()\ndf[\"NAME_EDUCATION_TYPE\"].value_counts()\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n\ndef cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\n\n\nfor col in cat_cols:\n    cat_summary(df, col)\n\n###################\n# 2. Rare kategoriler ile bağımlı değişken arasındaki ilişkinin analiz edilmesi.\n###################\n\ndf[\"NAME_INCOME_TYPE\"].value_counts()\n\ndf.groupby(\"NAME_INCOME_TYPE\")[\"TARGET\"].mean()\n\n\ndef rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() / len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\nrare_analyser(df, \"TARGET\", cat_cols)\n\n#############################################\n# 3. Rare encoder'ın yazılması.\n#############################################\n\ndef rare_encoder(dataframe, rare_perc):\n    temp_df = dataframe.copy()\n\n    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n                    and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() / len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n\n    return temp_df\n\nnew_df = rare_encoder(df, 0.01)\n\nrare_analyser(new_df, \"TARGET\", cat_cols)\n\ndf[\"OCCUPATION_TYPE\"].value_counts()\n\n\n#############################################\n# Feature Scaling (Özellik Ölçeklendirme)\n#############################################\n\n###################\n# StandardScaler: Klasik standartlaştırma. Ortalamayı çıkar, standart sapmaya böl. z = (x - u) / s\n###################\n\ndf = load()\nss = StandardScaler()\ndf[\"Age_standard_scaler\"] = ss.fit_transform(df[[\"Age\"]])\ndf.head()\n\n\n###################\n# RobustScaler: Medyanı çıkar iqr'a böl.\n###################\n\nrs = RobustScaler()\ndf[\"Age_robuts_scaler\"] = rs.fit_transform(df[[\"Age\"]])\ndf.describe().T\n\n###################\n# MinMaxScaler: Verilen 2 değer arasında değişken dönüşümü\n###################\n\n# X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n# X_scaled = X_std * (max - min) + min\n\nmms = MinMaxScaler()\ndf[\"Age_min_max_scaler\"] = mms.fit_transform(df[[\"Age\"]])\ndf.describe().T\n\ndf.head()\n\nage_cols = [col for col in df.columns if \"Age\" in col]\n\ndef num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show(block=True)\n\nfor col in age_cols:\n    num_summary(df, col, plot=True)\n\n###################\n# Numeric to Categorical: Sayısal Değişkenleri Kateorik Değişkenlere Çevirme\n# Binning\n###################\n\ndf[\"Age_qcut\"] = pd.qcut(df['Age'], 5)\n\n#############################################\n# Feature Extraction (Özellik Çıkarımı)\n#############################################\n\n#############################################\n# Binary Features: Flag, Bool, True-False\n#############################################\n\ndf = load()\ndf.head()\n\ndf[\"NEW_CABIN_BOOL\"] = df[\"Cabin\"].notnull().astype('int')\n\ndf.groupby(\"NEW_CABIN_BOOL\").agg({\"Survived\": \"mean\"})\n\n\nfrom statsmodels.stats.proportion import proportions_ztest\n\ntest_stat, pvalue = proportions_ztest(count=[df.loc[df[\"NEW_CABIN_BOOL\"] == 1, \"Survived\"].sum(),\n                                             df.loc[df[\"NEW_CABIN_BOOL\"] == 0, \"Survived\"].sum()],\n\n                                      nobs=[df.loc[df[\"NEW_CABIN_BOOL\"] == 1, \"Survived\"].shape[0],\n                                            df.loc[df[\"NEW_CABIN_BOOL\"] == 0, \"Survived\"].shape[0]])\n\nprint('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n\n\ndf.loc[((df['SibSp'] + df['Parch']) > 0), \"NEW_IS_ALONE\"] = \"NO\"\ndf.loc[((df['SibSp'] + df['Parch']) == 0), \"NEW_IS_ALONE\"] = \"YES\"\n\ndf.groupby(\"NEW_IS_ALONE\").agg({\"Survived\": \"mean\"})\n\n\ntest_stat, pvalue = proportions_ztest(count=[df.loc[df[\"NEW_IS_ALONE\"] == \"YES\", \"Survived\"].sum(),\n                                             df.loc[df[\"NEW_IS_ALONE\"] == \"NO\", \"Survived\"].sum()],\n\n                                      nobs=[df.loc[df[\"NEW_IS_ALONE\"] == \"YES\", \"Survived\"].shape[0],\n                                            df.loc[df[\"NEW_IS_ALONE\"] == \"NO\", \"Survived\"].shape[0]])\n\nprint('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n\n#############################################\n# Text'ler Üzerinden Özellik Türetmek\n#############################################\n\ndf.head()\n\n###################\n# Letter Count\n###################\n\ndf[\"NEW_NAME_COUNT\"] = df[\"Name\"].str.len()\n\n###################\n# Word Count\n###################\n\ndf[\"NEW_NAME_WORD_COUNT\"] = df[\"Name\"].apply(lambda x: len(str(x).split(\" \")))\n\n###################\n# Özel Yapıları Yakalamak\n###################\n\ndf[\"NEW_NAME_DR\"] = df[\"Name\"].apply(lambda x: len([x for x in x.split() if x.startswith(\"Dr\")]))\n\ndf.groupby(\"NEW_NAME_DR\").agg({\"Survived\": [\"mean\",\"count\"]})\n\n###################\n# Regex ile Değişken Türetmek\n###################\n\ndf.head()\n\ndf['NEW_TITLE'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n\ndf[[\"NEW_TITLE\", \"Survived\", \"Age\"]].groupby([\"NEW_TITLE\"]).agg({\"Survived\": \"mean\", \"Age\": [\"count\", \"mean\"]})\n\n#############################################\n# Date Değişkenleri Üretmek\n#############################################\n\ndff = pd.read_csv(\"/Users/ry/PycharmProjects/pythonProject/pythonProgramlama/python_for_data_science/feature_engineering/datasets/course_reviews.csv\")\ndff.head()\ndff.info()\n\ndff['Timestamp'] = pd.to_datetime(dff[\"Timestamp\"], format=\"%Y-%m-%d\")\n\n# year\ndff['year'] = dff['Timestamp'].dt.year\n\n# month\ndff['month'] = dff['Timestamp'].dt.month\n\n# year diff\ndff['year_diff'] = date.today().year - dff['Timestamp'].dt.year\n\n# month diff (iki tarih arasındaki ay farkı): yıl farkı + ay farkı\ndff['month_diff'] = (date.today().year - dff['Timestamp'].dt.year) * 12 + date.today().month - dff['Timestamp'].dt.month\n\n\n# day name\ndff['day_name'] = dff['Timestamp'].dt.day_name()\n\ndff.head()\n\n# date\n\n\n#############################################\n# Feature Interactions (Özellik Etkileşimleri)\n#############################################\ndf = load()\ndf.head()\n\ndf[\"NEW_AGE_PCLASS\"] = df[\"Age\"] * df[\"Pclass\"]\n\ndf[\"NEW_FAMILY_SIZE\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n\ndf.loc[(df['SEX'] == 'male') & (df['Age'] <= 21), 'NEW_SEX_CAT'] = 'youngmale'\n\ndf.loc[(df['SEX'] == 'male') & (df['Age'] > 21) & (df['Age'] < 50), 'NEW_SEX_CAT'] = 'maturemale'\n\ndf.loc[(df['SEX'] == 'male') & (df['Age'] >= 50), 'NEW_SEX_CAT'] = 'seniormale'\n\ndf.loc[(df['SEX'] == 'female') & (df['Age'] <= 21), 'NEW_SEX_CAT'] = 'youngfemale'\n\ndf.loc[(df['SEX'] == 'female') & (df['Age'] > 21) & (df['Age'] < 50), 'NEW_SEX_CAT'] = 'maturefemale'\n\ndf.loc[(df['SEX'] == 'female') & (df['Age'] >= 50), 'NEW_SEX_CAT'] = 'seniorfemale'\n\n\ndf.head()\n\ndf.groupby(\"NEW_SEX_CAT\")[\"Survived\"].mean()\n\n\n#############################################\n# Titanic Uçtan Uca Feature Engineering & Data Preprocessing\n#############################################\n\ndf = load()\ndf.shape\ndf.head()\n\ndf.columns = [col.upper() for col in df.columns]\n\n#############################################\n# 1. Feature Engineering (Değişken Mühendisliği)\n#############################################\n\n# Cabin bool\ndf[\"NEW_CABIN_BOOL\"] = df[\"CABIN\"].notnull().astype('int')\n# Name count\ndf[\"NEW_NAME_COUNT\"] = df[\"NAME\"].str.len()\n# name word count\ndf[\"NEW_NAME_WORD_COUNT\"] = df[\"NAME\"].apply(lambda x: len(str(x).split(\" \")))\n# name dr\ndf[\"NEW_NAME_DR\"] = df[\"NAME\"].apply(lambda x: len([x for x in x.split() if x.startswith(\"Dr\")]))\n# name title\ndf['NEW_TITLE'] = df.NAME.str.extract(' ([A-Za-z]+)\\.', expand=False)\n# family size\ndf[\"NEW_FAMILY_SIZE\"] = df[\"SIBSP\"] + df[\"PARCH\"] + 1\n# age_pclass\ndf[\"NEW_AGE_PCLASS\"] = df[\"AGE\"] * df[\"PCLASS\"]\n# is alone\ndf.loc[((df['SIBSP'] + df['PARCH']) > 0), \"NEW_IS_ALONE\"] = \"NO\"\ndf.loc[((df['SIBSP'] + df['PARCH']) == 0), \"NEW_IS_ALONE\"] = \"YES\"\n# age level\ndf.loc[(df['AGE'] < 18), 'NEW_AGE_CAT'] = 'young'\ndf.loc[(df['AGE'] >= 18) & (df['AGE'] < 56), 'NEW_AGE_CAT'] = 'mature'\ndf.loc[(df['AGE'] >= 56), 'NEW_AGE_CAT'] = 'senior'\n# sex x age\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngmale'\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] > 21) & (df['AGE'] < 50), 'NEW_SEX_CAT'] = 'maturemale'\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] >= 50), 'NEW_SEX_CAT'] = 'seniormale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngfemale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] > 21) & (df['AGE'] < 50), 'NEW_SEX_CAT'] = 'maturefemale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] >= 50), 'NEW_SEX_CAT'] = 'seniorfemale'\n\ndf.head()\ndf.shape\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nnum_cols = [col for col in num_cols if \"PASSENGERID\" not in col]\n\n#############################################\n# 2. Outliers (Aykırı Değerler)\n#############################################\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))\n\nfor col in num_cols:\n    replace_with_thresholds(df, col)\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))\n\n#############################################\n# 3. Missing Values (Eksik Değerler)\n#############################################\n\nmissing_values_table(df)\n\ndf.drop(\"CABIN\", inplace=True, axis=1)\n\nremove_cols = [\"TICKET\", \"NAME\"]\ndf.drop(remove_cols, inplace=True, axis=1)\n\n\ndf[\"AGE\"] = df[\"AGE\"].fillna(df.groupby(\"NEW_TITLE\")[\"AGE\"].transform(\"median\"))\n\n\ndf[\"NEW_AGE_PCLASS\"] = df[\"AGE\"] * df[\"PCLASS\"]\n\ndf.loc[(df['AGE'] < 18), 'NEW_AGE_CAT'] = 'young'\ndf.loc[(df['AGE'] >= 18) & (df['AGE'] < 56), 'NEW_AGE_CAT'] = 'mature'\ndf.loc[(df['AGE'] >= 56), 'NEW_AGE_CAT'] = 'senior'\n\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngmale'\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] > 21) & (df['AGE'] < 50), 'NEW_SEX_CAT'] = 'maturemale'\ndf.loc[(df['SEX'] == 'male') & (df['AGE'] >= 50), 'NEW_SEX_CAT'] = 'seniormale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] <= 21), 'NEW_SEX_CAT'] = 'youngfemale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] > 21) & (df['AGE'] < 50), 'NEW_SEX_CAT'] = 'maturefemale'\ndf.loc[(df['SEX'] == 'female') & (df['AGE'] >= 50), 'NEW_SEX_CAT'] = 'seniorfemale'\n\n\ndf = df.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= 10) else x, axis=0)\n\n#############################################\n# 4. Label Encoding\n#############################################\n\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2]\n\nfor col in binary_cols:\n    df = label_encoder(df, col)\n\n\n#############################################\n# 5. Rare Encoding\n#############################################\n\nrare_analyser(df, \"SURVIVED\", cat_cols)\n\n\ndf = rare_encoder(df, 0.01)\n\ndf[\"NEW_TITLE\"].value_counts()\n\n#############################################\n# 6. One-Hot Encoding\n#############################################\n\nohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]\n\ndf = one_hot_encoder(df, ohe_cols)\n\ndf.head()\ndf.shape\n\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nnum_cols = [col for col in num_cols if \"PASSENGERID\" not in col]\n\nrare_analyser(df, \"SURVIVED\", cat_cols)\n\nuseless_cols = [col for col in df.columns if df[col].nunique() == 2 and\n                (df[col].value_counts() / len(df) < 0.01).any(axis=None)]\n\n# df.drop(useless_cols, axis=1, inplace=True)\n\n#############################################\n# 7. Standart Scaler\n#############################################\n\nscaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n\ndf[num_cols].head()\n\ndf.head()\ndf.shape\n\n\n#############################################\n# 8. Model\n#############################################\n\ny = df[\"SURVIVED\"]\nX = df.drop([\"PASSENGERID\", \"SURVIVED\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(random_state=46).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_pred, y_test)\n\n#############################################\n# Hiç bir işlem yapılmadan elde edilecek skor?\n#############################################\n\ndff = load()\ndff.dropna(inplace=True)\ndff = pd.get_dummies(dff, columns=[\"Sex\", \"Embarked\"], drop_first=True)\ny = dff[\"Survived\"]\nX = dff.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)\nrf_model = RandomForestClassifier(random_state=46).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_pred, y_test)\n\n# Yeni ürettiğimiz değişkenler ne alemde?\n\ndef plot_importance(model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                      ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')\n\n\nplot_importance(rf_model, X_train)\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}