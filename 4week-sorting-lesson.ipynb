{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ryavuz/4week-sorting-lesson?scriptVersionId=197051077\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"###################################################\n# Sorting Products\n###################################################\n\n###################################################\n# Uygulama: Kurs Sıralama\n###################################################\nimport pandas as pd\nimport math\nimport scipy.stats as st\nfrom sklearn.preprocessing import MinMaxScaler\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\ndf = pd.read_csv(\"datasets/product_sorting.csv\")\nprint(df.shape)\ndf.head(10)\n\n####################\n# Sorting by Rating\n####################\n\ndf.sort_values(\"rating\", ascending=False).head(20)\n\n####################\n# Sorting by Comment Count or Purchase Count\n####################\n\ndf.sort_values(\"purchase_count\", ascending=False).head(20)\ndf.sort_values(\"commment_count\", ascending=False).head(20)\n\n####################\n# Sorting by Rating, Comment and Purchase\n####################\n\ndf[\"purchase_count_scaled\"] = MinMaxScaler(feature_range=(1, 5)). \\\n    fit(df[[\"purchase_count\"]]). \\\n    transform(df[[\"purchase_count\"]])\n\ndf.describe().T\n\ndf[\"comment_count_scaled\"] = MinMaxScaler(feature_range=(1, 5)). \\\n    fit(df[[\"commment_count\"]]). \\\n    transform(df[[\"commment_count\"]])\n\n(df[\"comment_count_scaled\"] * 32 / 100 +\n df[\"purchase_count_scaled\"] * 26 / 100 +\n df[\"rating\"] * 42 / 100)\n\n\ndef weighted_sorting_score(dataframe, w1=32, w2=26, w3=42):\n    return (dataframe[\"comment_count_scaled\"] * w1 / 100 +\n            dataframe[\"purchase_count_scaled\"] * w2 / 100 +\n            dataframe[\"rating\"] * w3 / 100)\n\n\ndf[\"weighted_sorting_score\"] = weighted_sorting_score(df)\n\ndf.sort_values(\"weighted_sorting_score\", ascending=False).head(20)\n\ndf[df[\"course_name\"].str.contains(\"Veri Bilimi\")].sort_values(\"weighted_sorting_score\", ascending=False).head(20)\n\n\n####################\n# Bayesian Average Rating Score\n####################\n\n# Sorting Products with 5 Star Rated\n# Sorting Products According to Distribution of 5 Star Rating\n\ndef bayesian_average_rating(n, confidence=0.95):\n    if sum(n) == 0:\n        return 0\n    K = len(n)\n    z = st.norm.ppf(1 - (1 - confidence) / 2)\n    N = sum(n)\n    first_part = 0.0\n    second_part = 0.0\n    for k, n_k in enumerate(n):\n        first_part += (k + 1) * (n[k] + 1) / (N + K)\n        second_part += (k + 1) * (k + 1) * (n[k] + 1) / (N + K)\n    score = first_part - z * math.sqrt((second_part - first_part * first_part) / (N + K + 1))\n    return score\n\n\ndf.head()\n\ndf[\"bar_score\"] = df.apply(lambda x: bayesian_average_rating(x[[\"1_point\",\n                                                                \"2_point\",\n                                                                \"3_point\",\n                                                                \"4_point\",\n                                                                \"5_point\"]]), axis=1)\n\ndf.sort_values(\"weighted_sorting_score\", ascending=False).head(20)\ndf.sort_values(\"bar_score\", ascending=False).head(20)\n\ndf[df[\"course_name\"].index.isin([5, 1])].sort_values(\"bar_score\", ascending=False)\n\n\n####################\n# Hybrid Sorting: BAR Score + Diğer Faktorler\n####################\n\n# Rating Products\n# - Average\n# - Time-Based Weighted Average\n# - User-Based Weighted Average\n# - Weighted Rating\n# - Bayesian Average Rating Score\n\n# Sorting Products\n# - Sorting by Rating\n# - Sorting by Comment Count or Purchase Count\n# - Sorting by Rating, Comment and Purchase\n# - Sorting by Bayesian Average Rating Score (Sorting Products with 5 Star Rated)\n# - Hybrid Sorting: BAR Score + Diğer Faktorler\n\n\ndef hybrid_sorting_score(dataframe, bar_w=60, wss_w=40):\n    bar_score = dataframe.apply(lambda x: bayesian_average_rating(x[[\"1_point\",\n                                                                     \"2_point\",\n                                                                     \"3_point\",\n                                                                     \"4_point\",\n                                                                     \"5_point\"]]), axis=1)\n    wss_score = weighted_sorting_score(dataframe)\n\n    return bar_score*bar_w/100 + wss_score*wss_w/100\n\n\ndf[\"hybrid_sorting_score\"] = hybrid_sorting_score(df)\n\ndf.sort_values(\"hybrid_sorting_score\", ascending=False).head(20)\n\ndf[df[\"course_name\"].str.contains(\"Veri Bilimi\")].sort_values(\"hybrid_sorting_score\", ascending=False).head(20)\n\n\n############################################\n# Uygulama: IMDB Movie Scoring & Sorting\n############################################\n\nimport pandas as pd\nimport math\nimport scipy.stats as st\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\ndf = pd.read_csv(\"datasets/movies_metadata.csv\",\n                 low_memory=False)  # DtypeWarning kapamak icin\n\ndf = df[[\"title\", \"vote_average\", \"vote_count\"]]\n\ndf.head()\ndf.shape\n\n########################\n# Vote Average'a Göre Sıralama\n########################\n\ndf.sort_values(\"vote_average\", ascending=False).head(20)\n\ndf[\"vote_count\"].describe([0.10, 0.25, 0.50, 0.70, 0.80, 0.90, 0.95, 0.99]).T\n\ndf[df[\"vote_count\"] > 400].sort_values(\"vote_average\", ascending=False).head(20)\n\nfrom sklearn.preprocessing import MinMaxScaler\n\ndf[\"vote_count_score\"] = MinMaxScaler(feature_range=(1, 10)). \\\n    fit(df[[\"vote_count\"]]). \\\n    transform(df[[\"vote_count\"]])\n\n########################\n# vote_average * vote_count\n########################\n\ndf[\"average_count_score\"] = df[\"vote_average\"] * df[\"vote_count_score\"]\n\ndf.sort_values(\"average_count_score\", ascending=False).head(20)\n\n\n########################\n# IMDB Weighted Rating\n########################\n\n\n# weighted_rating = (v/(v+M) * r) + (M/(v+M) * C)\n\n# r = vote average\n# v = vote count\n# M = minimum votes required to be listed in the Top 250\n# C = the mean vote across the whole report (currently 7.0)\n\n# Film 1:\n# r = 8\n# M = 500\n# v = 1000\n\n# (1000 / (1000+500))*8 = 5.33\n\n\n# Film 2:\n# r = 8\n# M = 500\n# v = 3000\n\n# (3000 / (3000+500))*8 = 6.85\n\n# (1000 / (1000+500))*9.5\n\n# Film 1:\n# r = 8\n# M = 500\n# v = 1000\n\n# Birinci bölüm:\n# (1000 / (1000+500))*8 = 5.33\n\n# İkinci bölüm:\n# 500/(1000+500) * 7 = 2.33\n\n# Toplam = 5.33 + 2.33 = 7.66\n\n\n# Film 2:\n# r = 8\n# M = 500\n# v = 3000\n\n# Birinci bölüm:\n# (3000 / (3000+500))*8 = 6.85\n\n# İkinci bölüm:\n# 500/(3000+500) * 7 = 1\n\n# Toplam = 7.85\n\nM = 2500\nC = df['vote_average'].mean()\n\ndef weighted_rating(r, v, M, C):\n    return (v / (v + M) * r) + (M / (v + M) * C)\n\ndf.sort_values(\"average_count_score\", ascending=False).head(10)\n\nweighted_rating(7.40000, 11444.00000, M, C)\n\nweighted_rating(8.10000, 14075.00000, M, C)\n\nweighted_rating(8.50000, 8358.00000, M, C)\n\ndf[\"weighted_rating\"] = weighted_rating(df[\"vote_average\"],\n                                        df[\"vote_count\"], M, C)\n\ndf.sort_values(\"weighted_rating\", ascending=False).head(10)\n\n####################\n# Bayesian Average Rating Score\n####################\n\n# 12481                                    The Dark Knight\n# 314                             The Shawshank Redemption\n# 2843                                          Fight Club\n# 15480                                          Inception\n# 292                                         Pulp Fiction\n\n\n\ndef bayesian_average_rating(n, confidence=0.95):\n    if sum(n) == 0:\n        return 0\n    K = len(n)\n    z = st.norm.ppf(1 - (1 - confidence) / 2)\n    N = sum(n)\n    first_part = 0.0\n    second_part = 0.0\n    for k, n_k in enumerate(n):\n        first_part += (k + 1) * (n[k] + 1) / (N + K)\n        second_part += (k + 1) * (k + 1) * (n[k] + 1) / (N + K)\n    score = first_part - z * math.sqrt((second_part - first_part * first_part) / (N + K + 1))\n    return score\n\nbayesian_average_rating([34733, 4355, 4704, 6561, 13515, 26183, 87368, 273082, 600260, 1295351])\n\nbayesian_average_rating([37128, 5879, 6268, 8419, 16603, 30016, 78538, 199430, 402518, 837905])\n\ndf = pd.read_csv(\"datasets/imdb_ratings.csv\")\ndf = df.iloc[0:, 1:]\n\n\ndf[\"bar_score\"] = df.apply(lambda x: bayesian_average_rating(x[[\"one\", \"two\", \"three\", \"four\", \"five\",\n                                                                \"six\", \"seven\", \"eight\", \"nine\", \"ten\"]]), axis=1)\ndf.sort_values(\"bar_score\", ascending=False).head(20)\n\n\n# Weighted Average Ratings\n# IMDb publishes weighted vote averages rather than raw data averages.\n# The simplest way to explain it is that although we accept and consider all votes received by users,\n# not all votes have the same impact (or ‘weight’) on the final rating.\n\n# When unusual voting activity is detected,\n# an alternate weighting calculation may be applied in order to preserve the reliability of our system.\n# To ensure that our rating mechanism remains effective,\n# we do not disclose the exact method used to generate the rating.\n#\n# See also the complete FAQ for IMDb ratings.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}